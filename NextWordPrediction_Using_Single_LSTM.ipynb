{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ao4Pj7BcRz6i"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import pickle\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "RiY09BdASm5U",
        "outputId": "2833ca56-16a4-4358-9e43-f872fbbf455c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b9610b02-c51d-4ead-85d2-e687507c9b90\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b9610b02-c51d-4ead-85d2-e687507c9b90\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Pride_and_Prejudice.txt to Pride_and_Prejudice.txt\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "file = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELBbRdVhSn5M"
      },
      "outputs": [],
      "source": [
        "file = open(\"Pride_and_Prejudice.txt\", \"r\", encoding = \"utf8\")\n",
        "\n",
        "# store file in list\n",
        "lines = []\n",
        "for i in file:\n",
        "  lines.append(i)\n",
        "\n",
        "# Convert list to string\n",
        "data = \"\"\n",
        "for i in lines:\n",
        "  data = ''.join(lines)\n",
        "\n",
        "# replace unnecessary stuff with space\n",
        "data = data.replace('\\n', ' ').replace('\\r', ' ').replace('\\ufeff', ' ').replace('“', ' ').replace('”', ' ').replace('.', ' ').replace(',', ' ').replace(':', ' ')\n",
        "data = data.replace('[', ' ').replace(']', ' ').replace('(', ' ').replace(')', ' ').replace('_', ' ').replace('*', ' ').replace('#', ' ')\n",
        "data = data.replace('/', '').replace('!', ' ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "EPJ89dHCUfhw",
        "outputId": "a6b5dfd4-d561-40b7-8cca-274ac03f4ff5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'the project gutenberg ebook of pride and prejudice by jane austen this ebook is for the use of anyone anywhere in the united states and most other parts of the world at no cost and with almost no restrictions whatsoever you may copy it give it away or re-use it under the terms of the project gutenberg license included with this ebook or online at www gutenberg org if you are not located in the united states you will have to check the laws of the country where you are located before using this ebook title pride and prejudice author jane austen release date november 12 2022 ebook 1342 most recently updated march 14 2023 language english produced by chuck greif and the online distributed proofreading team at http www pgdp net this file was produced from images available at the internet archive start of the project gutenberg ebook pride and prejudice illustration george allen publisher 156 charing cross road london ruskin house illustration reading jane’s letters chap 34 pride and prejudice by jane austen with a preface by george saintsbury and illustrations by hugh thomson illustration 1894 ruskin 156 charing house cross road london george allen chiswick press --charles whittingham and co tooks court chancery lane london illustration to j comyns carr in acknowledgment of all i owe to his friendship and advice these illustrations are gratefully inscribed hugh thomson preface illustration walt whitman has somewhere a fine and just distinction between loving by allowance and loving with personal love this distinction applies to books as well as to men and women; and in the case of the not very numerous authors who are the objects of the personal affection it brings a curious consequence with it there is much more difference as to their best work than in the case of those others who are loved by allowance by convention and because it is felt to be the right and proper thing to love them and in the sect--fairly large and yet unusually choice--of austenians or janites there would probably be found partisans of the claim to primacy of almost every one of the novels to some the delightful freshness and humour of northanger abbey its completeness finish and entrain obscure the undoubted critical facts that its scale is small and its scheme after all that of burlesque or parody a kind in which the first rank is reached with difficulty persuasion relatively faint in tone and not enthralling in interest has devotees who exalt above all the others its exquisite delicacy and keeping the catastrophe of mansfield park is admittedly theatrical the hero and heroine are insipid and the author has almost wickedly destroyed all romantic interest by expressly admitting that edmund only took fanny because mary shocked him and that fanny might very likely have taken crawford if he had been a little more assiduous; yet the matchless rehearsal-scenes and the characters of mrs norris and others have secured i believe a considerable party for it sense and sensibility has perhaps the fewest out-and-out admirers; but it does not want them i suppose however that the majority of at least competent votes would all things considered be divided between emma and the present book; and perhaps the vulgar verdict if indeed a fondness for miss austen be not of itself a patent of exemption from any possible charge of vulgarity would go for emma it is the larger the more varied the more popular; the author had by the time of its composition seen rather more of the world and had improved her general though not her most peculiar and characteristic dialogue; such figures as miss bates as the eltons cannot but unite the suffrages of everybody on the other hand i for my part declare for pride and prejudice unhesitatingly it seems to me the most perfect the most characteristic the most eminently quintessential of its author’s works; and for this contention in such narrow space as is permitted to me i propose here to show cause in the first place the book it may be barely necessary to remind the reader was in its first shape written very early somewhere about 1796 when miss austen was barely twenty-one; though it was revised and finished at chawton some fifteen years later and was not published till 1813 only four years before her death i do not know whether in this combination of the fresh and vigorous projection of youth and the critical revision of middle life there may be traced the distinct superiority in point of construction which as it seems to me it possesses over all the others the plot though not elaborate is almost regular enough for fielding; hardly a character hardly an incident could be retrenched without loss to the story the elopement of lydia and wickham is not like that of crawford and mrs rushworth a coup de théâtre; it connects itself in the strictest way with the course of the story earlier and brings about the denouement with complete propriety all the minor passages--the loves of jane and bingley the advent of mr collins the visit to '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "#remove unnecessary spaces\n",
        "data = data.split()\n",
        "data = ' '.join(data)\n",
        "data = data.lower()\n",
        "data[:5000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSa9kJmwUfqX",
        "outputId": "732ab32d-1d3f-46c6-ab88-57437724d868"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "715090"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "len(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Js98gKVzUftZ"
      },
      "outputs": [],
      "source": [
        "#Tokenization:\n",
        "tokenizer = Tokenizer()  \n",
        "tokenizer.fit_on_texts([data])\n",
        "\n",
        "# saving the tokenizer for predict function\n",
        "# pickle.dump() and dumps() are used to serialize an object. The only difference between them is that dump() writes the data to a file, \n",
        "#    while dumps() represents it as a byte object. \n",
        "pickle.dump(tokenizer, open('token.pkl', 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ld3BH7J7bseO",
        "outputId": "70e5febd-6619-4ff9-8bc9-947900fa41c6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 182, 164, 1000, 3, 299, 4, 946, 30, 72, 710, 41, 1000, 23, 21]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "sequence_data = tokenizer.texts_to_sequences([data])[0]\n",
        "sequence_data[:15]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-L4C2Zod6hi",
        "outputId": "6b3d06aa-e900-4715-b83f-534d831f4c15"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "131231"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "len(sequence_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vBxoyiod6kg",
        "outputId": "bd170eba-9ff0-4042-f56c-7635dc3d275e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7255\n"
          ]
        }
      ],
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print(vocab_size) #.."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ri4E4GlIwc2",
        "outputId": "143858da-77ba-4275-87d4-2c4e0f388367"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The length of sequences are:  131226\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   1,  182,  164, 1000,    3,  299],\n",
              "       [ 182,  164, 1000,    3,  299,    4],\n",
              "       [ 164, 1000,    3,  299,    4,  946],\n",
              "       [1000,    3,  299,    4,  946,   30],\n",
              "       [   3,  299,    4,  946,   30,   72],\n",
              "       [ 299,    4,  946,   30,   72,  710],\n",
              "       [   4,  946,   30,   72,  710,   41],\n",
              "       [ 946,   30,   72,  710,   41, 1000],\n",
              "       [  30,   72,  710,   41, 1000,   23],\n",
              "       [  72,  710,   41, 1000,   23,   21]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "#z\n",
        "\n",
        "sequences = []\n",
        "\n",
        "for i in range(5, len(sequence_data)):\n",
        "  words = sequence_data[i-5: i+1]\n",
        "  sequences.append(words)\n",
        "\n",
        "print(\"The length of sequences are: \", len(sequences))\n",
        "sequences = np.array(sequences)\n",
        "sequences[:10] #use 5 words, get next word."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5GAkBYEIwfv"
      },
      "outputs": [],
      "source": [
        "X = []\n",
        "y = []\n",
        "\n",
        "\n",
        "for i in sequences:\n",
        "  X.append(i[0:5])\n",
        "  y.append(i[5])\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjQrz7zDIwjK",
        "outputId": "f6b8cd7f-e676-4f0b-8735-c578f7d94d81"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   1,  182,  164, 1000,    3],\n",
              "       [ 182,  164, 1000,    3,  299],\n",
              "       [ 164, 1000,    3,  299,    4],\n",
              "       ...,\n",
              "       [ 201, 4362, 7254,    2,  231],\n",
              "       [4362, 7254,    2,  231,  126],\n",
              "       [7254,    2,  231,  126,  524]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sGjIActJFVg",
        "outputId": "0c8a6bbe-64c2-4519-8911-0ec41e2f6f0c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(131226, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4Q8not7JFYd",
        "outputId": "a4a78043-02f6-46e3-c102-d720c9602a4d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 299,    4,  946, ...,  126,  524, 1756])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSv6825AJ988",
        "outputId": "a5c37c41-c0bf-4acd-a0b4-d6d7571bc4b0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "y = to_categorical(y, num_classes=vocab_size)\n",
        "y[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rT7iIAF3JFbx"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train,  y_test = train_test_split(X, y, test_size = 0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TUEHxIf1JFfv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d558d7e-a1c7-4746-8012-19b868945950"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "X_valid = []\n",
        "y_valid = []\n",
        "\n",
        "for i in range(3, len(sequence_data)-5, 6):\n",
        "  X_valid.append(sequence_data[i:i+5])\n",
        "  y_valid.append(sequence_data[i+5])\n",
        "\n",
        "X_valid = np.array(X_valid)\n",
        "y_valid = np.array(y_valid)\n",
        "y_valid = to_categorical(y_valid, num_classes=vocab_size)\n",
        "y_valid[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHp9VMA2JUhv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0909a84a-4b92-41cd-cc52-7e77a0228316"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(21871, 5)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1000,    3,  299,    4,  946],\n",
              "       [  72,  710,   41, 1000,   23],\n",
              "       [   1,  507,    3,  549, 2654],\n",
              "       ...,\n",
              "       [  78,    2,  363, 1945,  201],\n",
              "       [1756,    4,   78,    2, 7253],\n",
              "       [ 201, 4362, 7254,    2,  231]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "print(X_valid.shape)\n",
        "X_valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0QTGooMtJUko",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fda62f62-9e2c-438e-c5fc-ca037923c843"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(21871, 7255)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "print(y_valid.shape)\n",
        "y_valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p00x1SdikZlL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6ec6098-c115-4d71-8beb-63c83b5861fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 5, 10)             72550     \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 512)               1071104   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 7255)              3721815   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,865,469\n",
            "Trainable params: 4,865,469\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# simple LSTM\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Embedding, Dense, Flatten\n",
        "\n",
        "# vocabulary = 10000\n",
        "embedding_dim = 10\n",
        "word_num = 5\n",
        "# state_dim = 10\n",
        "\n",
        "# model = Sequential()\n",
        "# model.add(Embedding(vocabulary, embedding_dim, input_length=word_num))\n",
        "# model.add(LSTM(state_dim, return_sequences=False))\n",
        "# model.add(Dense(1, activation='softmax'))\n",
        "# model.summary()\n",
        "\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim, input_length=word_num))\n",
        "model.add(LSTM(512, return_sequences=False))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRZyPShDvTec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "outputId": "0c5f3b9e-3834-4caa-acf6-884440123d6a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "plot_model(model, to_file='plot.png', show_layer_names=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wxdnpGFzl3yg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3029fd73-c4a1-4303-8e80-db05e7231460"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "3281/3281 [==============================] - 495s 150ms/step - loss: 6.3051 - acc: 0.0556 - val_loss: 5.8211 - val_acc: 0.0868\n",
            "Epoch 2/50\n",
            "3281/3281 [==============================] - 479s 146ms/step - loss: 5.6412 - acc: 0.1003 - val_loss: 5.4271 - val_acc: 0.1161\n",
            "Epoch 3/50\n",
            "3281/3281 [==============================] - 475s 145ms/step - loss: 5.3027 - acc: 0.1221 - val_loss: 5.1616 - val_acc: 0.1303\n",
            "Epoch 4/50\n",
            "3281/3281 [==============================] - 476s 145ms/step - loss: 5.0143 - acc: 0.1349 - val_loss: 4.8924 - val_acc: 0.1462\n",
            "Epoch 5/50\n",
            "3281/3281 [==============================] - 469s 143ms/step - loss: 4.7027 - acc: 0.1473 - val_loss: 4.5899 - val_acc: 0.1633\n",
            "Epoch 6/50\n",
            "3281/3281 [==============================] - 473s 144ms/step - loss: 4.3536 - acc: 0.1657 - val_loss: 4.2586 - val_acc: 0.2046\n",
            "Epoch 7/50\n",
            "3281/3281 [==============================] - 470s 143ms/step - loss: 3.9681 - acc: 0.1975 - val_loss: 3.9456 - val_acc: 0.2500\n",
            "Epoch 8/50\n",
            "3281/3281 [==============================] - 467s 142ms/step - loss: 3.5620 - acc: 0.2463 - val_loss: 3.6333 - val_acc: 0.3054\n",
            "Epoch 9/50\n",
            "3281/3281 [==============================] - 472s 144ms/step - loss: 3.1575 - acc: 0.3061 - val_loss: 3.3591 - val_acc: 0.3671\n",
            "Epoch 10/50\n",
            "3281/3281 [==============================] - 471s 144ms/step - loss: 2.7700 - acc: 0.3740 - val_loss: 3.1175 - val_acc: 0.4266\n",
            "Epoch 11/50\n",
            "3281/3281 [==============================] - 473s 144ms/step - loss: 2.4025 - acc: 0.4447 - val_loss: 2.8739 - val_acc: 0.4860\n",
            "Epoch 12/50\n",
            "3281/3281 [==============================] - 473s 144ms/step - loss: 2.0641 - acc: 0.5165 - val_loss: 2.7016 - val_acc: 0.5403\n",
            "Epoch 13/50\n",
            "3281/3281 [==============================] - 474s 145ms/step - loss: 1.7484 - acc: 0.5870 - val_loss: 2.5250 - val_acc: 0.5938\n",
            "Epoch 14/50\n",
            "3281/3281 [==============================] - 480s 146ms/step - loss: 1.4659 - acc: 0.6523 - val_loss: 2.4029 - val_acc: 0.6371\n",
            "Epoch 15/50\n",
            "3281/3281 [==============================] - 475s 145ms/step - loss: 1.2148 - acc: 0.7141 - val_loss: 2.2899 - val_acc: 0.6796\n",
            "Epoch 16/50\n",
            "3281/3281 [==============================] - 478s 146ms/step - loss: 0.9911 - acc: 0.7694 - val_loss: 2.2212 - val_acc: 0.7077\n",
            "Epoch 17/50\n",
            "3281/3281 [==============================] - 481s 147ms/step - loss: 0.8024 - acc: 0.8163 - val_loss: 2.1672 - val_acc: 0.7341\n",
            "Epoch 18/50\n",
            "3281/3281 [==============================] - 472s 144ms/step - loss: 0.6444 - acc: 0.8564 - val_loss: 2.1514 - val_acc: 0.7520\n",
            "Epoch 19/50\n",
            "3281/3281 [==============================] - 474s 144ms/step - loss: 0.5207 - acc: 0.8880 - val_loss: 2.1487 - val_acc: 0.7630\n",
            "Epoch 20/50\n",
            "3281/3281 [==============================] - 478s 146ms/step - loss: 0.4260 - acc: 0.9107 - val_loss: 2.1555 - val_acc: 0.7742\n",
            "Epoch 21/50\n",
            "3281/3281 [==============================] - 474s 144ms/step - loss: 0.3549 - acc: 0.9279 - val_loss: 2.1733 - val_acc: 0.7818\n",
            "Epoch 22/50\n",
            "3281/3281 [==============================] - 480s 146ms/step - loss: 0.2987 - acc: 0.9415 - val_loss: 2.2098 - val_acc: 0.7806\n",
            "Epoch 23/50\n",
            "3281/3281 [==============================] - 490s 149ms/step - loss: 0.2696 - acc: 0.9475 - val_loss: 2.2448 - val_acc: 0.7854\n",
            "Epoch 24/50\n",
            "3281/3281 [==============================] - 487s 149ms/step - loss: 0.2439 - acc: 0.9514 - val_loss: 2.2693 - val_acc: 0.7869\n",
            "Epoch 25/50\n",
            "3281/3281 [==============================] - 483s 147ms/step - loss: 0.2207 - acc: 0.9561 - val_loss: 2.3031 - val_acc: 0.7877\n",
            "Epoch 26/50\n",
            "3281/3281 [==============================] - 483s 147ms/step - loss: 0.2095 - acc: 0.9583 - val_loss: 2.3295 - val_acc: 0.7888\n",
            "Epoch 27/50\n",
            "3281/3281 [==============================] - 483s 147ms/step - loss: 0.1978 - acc: 0.9602 - val_loss: 2.3631 - val_acc: 0.7871\n",
            "Epoch 28/50\n",
            "3281/3281 [==============================] - 486s 148ms/step - loss: 0.1907 - acc: 0.9601 - val_loss: 2.3797 - val_acc: 0.7903\n",
            "Epoch 29/50\n",
            "3281/3281 [==============================] - 473s 144ms/step - loss: 0.1824 - acc: 0.9614 - val_loss: 2.4203 - val_acc: 0.7857\n",
            "Epoch 30/50\n",
            "3281/3281 [==============================] - 475s 145ms/step - loss: 0.1761 - acc: 0.9632 - val_loss: 2.4368 - val_acc: 0.7897\n",
            "Epoch 31/50\n",
            "3281/3281 [==============================] - 471s 144ms/step - loss: 0.1735 - acc: 0.9630 - val_loss: 2.4538 - val_acc: 0.7914\n",
            "Epoch 32/50\n",
            "3281/3281 [==============================] - 474s 145ms/step - loss: 0.1653 - acc: 0.9649 - val_loss: 2.4787 - val_acc: 0.7891\n",
            "Epoch 33/50\n",
            "3281/3281 [==============================] - 474s 145ms/step - loss: 0.1657 - acc: 0.9635 - val_loss: 2.4924 - val_acc: 0.7924\n",
            "Epoch 34/50\n",
            "3281/3281 [==============================] - 472s 144ms/step - loss: 0.1610 - acc: 0.9641 - val_loss: 2.4894 - val_acc: 0.7913\n",
            "Epoch 35/50\n",
            "3281/3281 [==============================] - 470s 143ms/step - loss: 0.1583 - acc: 0.9644 - val_loss: 2.5142 - val_acc: 0.7902\n",
            "Epoch 36/50\n",
            "3281/3281 [==============================] - 472s 144ms/step - loss: 0.1514 - acc: 0.9661 - val_loss: 2.5319 - val_acc: 0.7917\n",
            "Epoch 37/50\n",
            "3281/3281 [==============================] - 472s 144ms/step - loss: 0.1562 - acc: 0.9641 - val_loss: 2.5591 - val_acc: 0.7894\n",
            "Epoch 38/50\n",
            "3281/3281 [==============================] - 468s 143ms/step - loss: 0.1499 - acc: 0.9664 - val_loss: 2.5852 - val_acc: 0.7899\n",
            "Epoch 39/50\n",
            "3281/3281 [==============================] - 471s 144ms/step - loss: 0.1515 - acc: 0.9657 - val_loss: 2.5719 - val_acc: 0.7891\n",
            "Epoch 40/50\n",
            "3281/3281 [==============================] - 474s 145ms/step - loss: 0.1493 - acc: 0.9649 - val_loss: 2.6090 - val_acc: 0.7900\n",
            "Epoch 41/50\n",
            "3281/3281 [==============================] - 477s 145ms/step - loss: 0.1479 - acc: 0.9653 - val_loss: 2.6255 - val_acc: 0.7898\n",
            "Epoch 42/50\n",
            "3281/3281 [==============================] - 475s 145ms/step - loss: 0.1453 - acc: 0.9658 - val_loss: 2.6234 - val_acc: 0.7903\n",
            "Epoch 43/50\n",
            "3281/3281 [==============================] - 475s 145ms/step - loss: 0.1454 - acc: 0.9658 - val_loss: 2.6532 - val_acc: 0.7894\n",
            "Epoch 44/50\n",
            "3281/3281 [==============================] - 476s 145ms/step - loss: 0.1452 - acc: 0.9651 - val_loss: 2.6807 - val_acc: 0.7882\n",
            "Epoch 45/50\n",
            "3281/3281 [==============================] - 479s 146ms/step - loss: 0.1423 - acc: 0.9653 - val_loss: 2.6991 - val_acc: 0.7889\n",
            "Epoch 46/50\n",
            "3281/3281 [==============================] - 476s 145ms/step - loss: 0.1410 - acc: 0.9661 - val_loss: 2.6926 - val_acc: 0.7904\n",
            "Epoch 47/50\n",
            "3281/3281 [==============================] - 473s 144ms/step - loss: 0.1412 - acc: 0.9659 - val_loss: 2.6989 - val_acc: 0.7905\n",
            "Epoch 48/50\n",
            "3281/3281 [==============================] - 470s 143ms/step - loss: 0.1442 - acc: 0.9649 - val_loss: 2.7053 - val_acc: 0.7926\n",
            "Epoch 49/50\n",
            "3281/3281 [==============================] - 469s 143ms/step - loss: 0.1367 - acc: 0.9663 - val_loss: 2.7233 - val_acc: 0.7902\n",
            "Epoch 50/50\n",
            "2471/3281 [=====================>........] - ETA: 1:51 - loss: 0.1224 - acc: 0.9708"
          ]
        }
      ],
      "source": [
        "from keras import optimizers\n",
        "\n",
        "epochs = 50\n",
        "\n",
        "# model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "# model.fit(X_train, y_train, epochs=epochs, batch_size=32, validation_data=(X_valid, y_valid))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "# checkpoint = ModelCheckpoint(\"next_words.h5\", monitor='loss', verbose=1, save_best_only=True)\n",
        "# model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate=0.001))\n",
        "# model.fit(X, y, epochs=10, batch_size=64, callbacks=[checkpoint])\n",
        "\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=epochs, batch_size=32, validation_data=(X_valid, y_valid))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LncrnWSMm_qa"
      },
      "outputs": [],
      "source": [
        "# Prediction\n",
        "\n",
        "def Prediction_next_word(text):\n",
        "  sequence_text = tokenizer.texts_to_sequences([text])\n",
        "  sequence_text = np.array(sequence_text)\n",
        "  preds = np.argmax(model.predict(sequence_text))\n",
        "  predicted_word = \"\"\n",
        "\n",
        "  for key, value in tokenizer.word_index.items():\n",
        "    if value==preds:\n",
        "      predicted_word = key\n",
        "      break\n",
        "  \n",
        "  print(predicted_word)\n",
        "  return predicted_word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wdG5cnTwOoHT"
      },
      "outputs": [],
      "source": [
        "while(True):\n",
        "  text = input(\"Enter your line: \")\n",
        "\n",
        "  if text == \"0\":\n",
        "    print(\"Excution completed.\")\n",
        "    break\n",
        "\n",
        "  else:\n",
        "    try:\n",
        "      text = text.split(\" \")\n",
        "      \n",
        "      text = text[-5:]\n",
        "      print(text)\n",
        "\n",
        "      Prediction_next_word(text)\n",
        "    \n",
        "    except Exception as e:\n",
        "      print(\"Error occured: \", e)\n",
        "      continue"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}